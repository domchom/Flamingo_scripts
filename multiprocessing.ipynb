{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import napari\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tifffile import imread as tiff_read\n",
    "from tifffile import imwrite as tiff_write\n",
    "from dask_image.imread import imread as dask_read\n",
    "import dask.array as da\n",
    "from dask import distributed\n",
    "import time\n",
    "from yaspin import yaspin\n",
    "from dask.distributed import Client\n",
    "# import dask delayed\n",
    "from dask.delayed import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Volumes/bigData/kkpo_test/mp_test'\n",
    "dask_max_path = '/Volumes/bigData/kkpo_test/mp_test/dask'\n",
    "dask_vol_path = '/Volumes/bigData/kkpo_test/mp_test/dask_vol.zarr'\n",
    "trad_max_path = '/Volumes/bigData/kkpo_test/mp_test/trad'\n",
    "trad_vol_path = '/Volumes/bigData/kkpo_test/mp_test/trad_vol'\n",
    "\n",
    "for path in [dask_max_path, dask_vol_path, trad_max_path, trad_vol_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S000_t000000_V000_R0000_X000_Y000_C01_I0_D0_P00192.tif',\n",
       " 'S000_t000001_V000_R0000_X000_Y000_C01_I0_D0_P00192.tif',\n",
       " 'S000_t000002_V000_R0000_X000_Y000_C02_I0_D0_P00192.tif',\n",
       " 'S000_t000003_V000_R0000_X000_Y000_C01_I0_D0_P00192.tif',\n",
       " 'S000_t000004_V000_R0000_X000_Y000_C01_I0_D0_P00192.tif']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [file for file in os.listdir(file_path) if file.endswith('.tif') and not file.startswith('.')]\n",
    "files.sort()\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current Kkpo version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gathered 5 images and assembled them into a dask array of shape (5, 192, 2048, 2048) with chunk size ((1, 1, 1, 1, 1), (192,), (2048,), (2048,))\n",
      "⠼\u001b[0m Converting full volume to zarr, please be patient...\u001b[KSaved channel zarr in 7.125 seconds\n",
      "\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving max projections: 100%|██████████| 5/5 [00:16<00:00,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.03 s, sys: 1.64 s, total: 4.67 s\n",
      "Wall time: 24.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ims = dask_read(file_path + '/' + '*.tif')\n",
    "print(f'gathered {len(ims)} images and assembled them into a dask array of shape {ims.shape} with chunk size {ims.chunks}')\n",
    "\n",
    "# save volume as zarr\n",
    "with yaspin() as sp:\n",
    "    sp.text = f'Converting full volume to zarr, please be patient...'\n",
    "    start = time.time()\n",
    "    da.to_zarr(ims[:,:,::8,::8], dask_vol_path, overwrite=True)\n",
    "    end = time.time()\n",
    "    print(f'Saved channel zarr in {round(end - start, 3)} seconds')\n",
    "\n",
    "# save max projection\n",
    "with tqdm(total=len(files)) as max_pbar:\n",
    "    max_pbar.set_description('Saving max projections')\n",
    "    for tp, tp_name in enumerate(['t000000', 't000001', 't000002', 't000003', 't000004']):\n",
    "        tiff_write(dask_max_path + '/' + f'{tp_name}_Max.tiff', np.max(ims[tp,:,:,:], axis=0))\n",
    "        max_pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### same thing but with distributed client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bementmbp/opt/anaconda3/envs/image-analysis/lib/python3.9/site-packages/distributed/node.py:177: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 54359 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:54360' processes=8 threads=16, memory=64.00 GiB>\n",
      "gathered 5 images and assembled them into a dask array of shape (5, 192, 2048, 2048) with chunk size ((1, 1, 1, 1, 1), (192,), (2048,), (2048,))\n",
      "⠴\u001b[0m Converting full volume to zarr, please be patient...\u001b[KSaved channel zarr in 8.865 seconds\n",
      "\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving max projections: 100%|██████████| 5/5 [00:20<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.58 s, sys: 2.58 s, total: 8.16 s\n",
      "Wall time: 31.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# make client with 16 processes\n",
    "client = Client(n_workers=8)\n",
    "print(client)\n",
    "\n",
    "ims = dask_read(file_path + '/' + '*.tif')\n",
    "print(f'gathered {len(ims)} images and assembled them into a dask array of shape {ims.shape} with chunk size {ims.chunks}')\n",
    "\n",
    "# save volume as zarr\n",
    "with yaspin() as sp:\n",
    "    sp.text = f'Converting full volume to zarr, please be patient...'\n",
    "    start = time.time()\n",
    "    da.to_zarr(ims[:,:,::8,::8], dask_vol_path, overwrite=True)\n",
    "    end = time.time()\n",
    "    print(f'Saved channel zarr in {round(end - start, 3)} seconds')\n",
    "\n",
    "# save max projection\n",
    "with tqdm(total=len(files)) as max_pbar:\n",
    "    max_pbar.set_description('Saving max projections')\n",
    "    for tp, tp_name in enumerate(['t000000', 't000001', 't000002', 't000003', 't000004']):\n",
    "        tiff_write(dask_max_path + '/' + f'{tp_name}_Max.tiff', np.max(ims[tp,:,:,:], axis=0))\n",
    "        max_pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with client and explicit parallelization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bementmbp/opt/anaconda3/envs/image-analysis/lib/python3.9/site-packages/distributed/node.py:177: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 54288 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:54289' processes=4 threads=16, memory=64.00 GiB>\n",
      "gathered 5 images and assembled them into a dask array of shape (5, 192, 2048, 2048) with chunk size ((1, 1, 1, 1, 1), (192,), (2048,), (2048,))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 08:04:37,123 - distributed.worker_memory - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "2022-07-08 08:04:37,737 - distributed.nanny - WARNING - Restarting worker\n",
      "2022-07-08 08:04:54,323 - distributed.worker_memory - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "2022-07-08 08:04:54,942 - distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:24\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/image-analysis/lib/python3.9/site-packages/dask/base.py:292\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    269\u001b[0m     \u001b[39m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \n\u001b[1;32m    271\u001b[0m \u001b[39m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39m    dask.base.compute\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m     (result,) \u001b[39m=\u001b[39m compute(\u001b[39mself\u001b[39;49m, traverse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    293\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/image-analysis/lib/python3.9/site-packages/dask/base.py:575\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m     keys\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_keys__())\n\u001b[1;32m    573\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 575\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    576\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/image-analysis/lib/python3.9/site-packages/distributed/client.py:3026\u001b[0m, in \u001b[0;36mClient.get\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   3024\u001b[0m         should_rejoin \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   3025\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3026\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgather(packed, asynchronous\u001b[39m=\u001b[39;49masynchronous, direct\u001b[39m=\u001b[39;49mdirect)\n\u001b[1;32m   3027\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m futures\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/image-analysis/lib/python3.9/site-packages/distributed/client.py:2179\u001b[0m, in \u001b[0;36mClient.gather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2177\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2178\u001b[0m     local_worker \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2179\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msync(\n\u001b[1;32m   2180\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gather,\n\u001b[1;32m   2181\u001b[0m     futures,\n\u001b[1;32m   2182\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   2183\u001b[0m     direct\u001b[39m=\u001b[39;49mdirect,\n\u001b[1;32m   2184\u001b[0m     local_worker\u001b[39m=\u001b[39;49mlocal_worker,\n\u001b[1;32m   2185\u001b[0m     asynchronous\u001b[39m=\u001b[39;49masynchronous,\n\u001b[1;32m   2186\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/image-analysis/lib/python3.9/site-packages/distributed/utils.py:309\u001b[0m, in \u001b[0;36mSyncMethodMixin.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[39mreturn\u001b[39;00m future\n\u001b[1;32m    308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m     \u001b[39mreturn\u001b[39;00m sync(\n\u001b[1;32m    310\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloop, func, \u001b[39m*\u001b[39;49margs, callback_timeout\u001b[39m=\u001b[39;49mcallback_timeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    311\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/image-analysis/lib/python3.9/site-packages/distributed/utils.py:372\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m e\u001b[39m.\u001b[39mis_set():\n\u001b[0;32m--> 372\u001b[0m         wait(\u001b[39m10\u001b[39;49m)\n\u001b[1;32m    374\u001b[0m \u001b[39mif\u001b[39;00m error:\n\u001b[1;32m    375\u001b[0m     typ, exc, tb \u001b[39m=\u001b[39m error\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/image-analysis/lib/python3.9/site-packages/distributed/utils.py:361\u001b[0m, in \u001b[0;36msync.<locals>.wait\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(timeout):\n\u001b[1;32m    360\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 361\u001b[0m         \u001b[39mreturn\u001b[39;00m e\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    362\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m         loop\u001b[39m.\u001b[39madd_callback(cancel)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/image-analysis/lib/python3.9/threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    573\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 574\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/image-analysis/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    317\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import skimage\n",
    "\n",
    "# make client with 16 processes\n",
    "client = Client()\n",
    "print(client)\n",
    "\n",
    "ims = dask_read(file_path + '/' + '*.tif')\n",
    "print(f'gathered {len(ims)} images and assembled them into a dask array of shape {ims.shape} with chunk size {ims.chunks}')\n",
    "\n",
    "#for tp, tp_name in enumerate(['t000000', 't000001', 't000002', 't000003', 't000004']):\n",
    "max = delayed(np.max(ims[:,:,:,:], axis=0))\n",
    "    #save = delayed(tiff_write(dask_max_path + '/' + f'{tp_name}_Max.tiff', max))\n",
    "\n",
    "def save_file(arr, block_info=None):\n",
    "    \"\"\" Save file to foo-x-y.tif, where x and y are block locations \"\"\"\n",
    "    filename = \"foo-\" + \"-\".join(map(str, block_info[0][\"chunk-location\"])) + \".tif\"\n",
    "    skimage.io.imsave(filename, arr)\n",
    "    return arr\n",
    "\n",
    "s = delayed(max.map_blocks(save_file, dtype=max.dtype))#.compute())       # call function on every block\n",
    "\n",
    "max.visualize()\n",
    "s.visualize()\n",
    "s.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('image-analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7ec4263e4001474e72c70f185906f427acb5774367a2b2d09b308b8269b701b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
