{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import napari\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tifffile import imread as tiff_read\n",
    "from tifffile import imwrite as tiff_write\n",
    "from dask_image.imread import imread as dask_read\n",
    "import dask.array as da\n",
    "from dask import distributed\n",
    "import time\n",
    "from yaspin import yaspin\n",
    "from dask.distributed import Client\n",
    "# import dask delayed\n",
    "from dask.delayed import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Volumes/bigData/kkpo_test/mp_test'\n",
    "dask_max_path = '/Volumes/bigData/kkpo_test/mp_test/dask'\n",
    "dask_vol_path = '/Volumes/bigData/kkpo_test/mp_test/dask_vol.zarr'\n",
    "trad_max_path = '/Volumes/bigData/kkpo_test/mp_test/trad'\n",
    "trad_vol_path = '/Volumes/bigData/kkpo_test/mp_test/trad_vol'\n",
    "\n",
    "for path in [dask_max_path, dask_vol_path, trad_max_path, trad_vol_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir(file_path) if file.endswith('.tif') and not file.startswith('.')]\n",
    "files.sort()\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current Kkpo version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ims = dask_read(file_path + '/' + '*.tif')\n",
    "print(f'gathered {len(ims)} images and assembled them into a dask array of shape {ims.shape} with chunk size {ims.chunks}')\n",
    "\n",
    "# save volume as zarr\n",
    "with yaspin() as sp:\n",
    "    sp.text = f'Converting full volume to zarr, please be patient...'\n",
    "    start = time.time()\n",
    "    da.to_zarr(ims[:,:,::8,::8], dask_vol_path, overwrite=True)\n",
    "    end = time.time()\n",
    "    print(f'Saved channel zarr in {round(end - start, 3)} seconds')\n",
    "\n",
    "# save max projection\n",
    "with tqdm(total=len(files)) as max_pbar:\n",
    "    max_pbar.set_description('Saving max projections')\n",
    "    for tp, tp_name in enumerate(['t000000', 't000001', 't000002', 't000003', 't000004']):\n",
    "        tiff_write(dask_max_path + '/' + f'{tp_name}_Max.tiff', np.max(ims[tp,:,:,:], axis=0))\n",
    "        max_pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interact.kkpo import Kkpo\n",
    "\n",
    "file_path = '/Volumes/bigData/kkpo_testing/1_region_2i'\n",
    "\n",
    "kkpo = Kkpo(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left off here:\n",
    "\n",
    "I need a better way to remove partial chunks. It may be possible to find the first time point (i.e, all the regions, channels, illuminations, etc), and then remove all the other time points that are not that first time point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving region 1/1\n",
      "Collecting information about region R0000\n",
      "num time points = 12\n",
      "/Volumes/bigData/kkpo_testing/1_region_2i/R0000_processed already exists. Overwriting file!\n",
      "Saving channel 1/3\n",
      "Multiple time points with two-sided illumination detected\n",
      "⠇\u001b[0m Fusing two-sided illumination and converting full volume for C00 to zarr, please be patient...\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[KSaved channel C00 in 51.682 seconds\n",
      "\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving max projections: 100%|██████████| 12/12 [00:28<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving channel 2/3\n",
      "Multiple time points with two-sided illumination detected\n",
      "⠦\u001b[0m Fusing two-sided illumination and converting full volume for C01 to zarr, please be patient...\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[KSaved channel C01 in 49.991 seconds\n",
      "\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving max projections:  92%|█████████▏| 11/12 [00:26<00:02,  2.39s/it]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Index is not smaller than dimension 11 >= 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 19\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m\"\"\"  \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m 'file_path',\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m 'files',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m 'view_volumes'\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m#print(kkpo.region_names[0])\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m#interval, timepoint_names, channel_names, illum_names, plane_names = kkpo.get_region_info(kkpo.region_names[0])\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m#print(interval, timepoint_names, channel_names, illum_names, plane_names)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m kkpo\u001b[39m.\u001b[39;49msave_regions(overwrite \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, save_vol \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Desktop/Scripts/Flamingo_scripts/interact/kkpo.py:220\u001b[0m, in \u001b[0;36mKkpo.save_regions\u001b[0;34m(self, save_vol, save_max, step, overwrite)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39mfor\u001b[39;00m tp, tp_name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(timepoint_names):\n\u001b[1;32m    219\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(illum_names) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 220\u001b[0m         tiff_write(region_save_path \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mregion_name\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mch_name\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mtp_name\u001b[39m}\u001b[39;00m\u001b[39m_Max.tiff\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mmaximum(np\u001b[39m.\u001b[39mmax(channel_array_left[tp], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), np\u001b[39m.\u001b[39mmax(channel_array_right[tp], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)))\n\u001b[1;32m    221\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m         \u001b[39mprint\u001b[39m(channel_array\u001b[39m.\u001b[39mshape, tp)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/kkpo-env/lib/python3.9/site-packages/dask/array/core.py:1714\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m   1706\u001b[0m     index \u001b[39m=\u001b[39m (index,)\n\u001b[1;32m   1708\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mslicing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m   1709\u001b[0m     normalize_index,\n\u001b[1;32m   1710\u001b[0m     slice_with_bool_dask_array,\n\u001b[1;32m   1711\u001b[0m     slice_with_int_dask_array,\n\u001b[1;32m   1712\u001b[0m )\n\u001b[0;32m-> 1714\u001b[0m index2 \u001b[39m=\u001b[39m normalize_index(index, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m   1715\u001b[0m dependencies \u001b[39m=\u001b[39m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname}\n\u001b[1;32m   1716\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m index2:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/kkpo-env/lib/python3.9/site-packages/dask/array/slicing.py:911\u001b[0m, in \u001b[0;36mnormalize_index\u001b[0;34m(idx, shape)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39mfor\u001b[39;00m i, d \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(idx, none_shape):\n\u001b[1;32m    910\u001b[0m     \u001b[39mif\u001b[39;00m d \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 911\u001b[0m         check_index(i, d)\n\u001b[1;32m    912\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mmap\u001b[39m(sanitize_index, idx))\n\u001b[1;32m    913\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mmap\u001b[39m(normalize_slice, idx, none_shape))\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/kkpo-env/lib/python3.9/site-packages/dask/array/slicing.py:981\u001b[0m, in \u001b[0;36mcheck_index\u001b[0;34m(ind, dimension)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m ind \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m dimension:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[1;32m    982\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIndex is not smaller than dimension \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m >= \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (ind, dimension)\n\u001b[1;32m    983\u001b[0m     )\n\u001b[1;32m    985\u001b[0m \u001b[39melif\u001b[39;00m ind \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mdimension:\n\u001b[1;32m    986\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNegative index is not greater than negative dimension \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m <= -\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: Index is not smaller than dimension 11 >= 11"
     ]
    }
   ],
   "source": [
    "from interact.kkpo import Kkpo\n",
    "\n",
    "file_path = '/Volumes/bigData/kkpo_testing/1_region_2i'\n",
    "\n",
    "kkpo = Kkpo(file_path)\n",
    "\"\"\"  \n",
    " 'file_path',\n",
    " 'files',\n",
    " 'get_region_info',\n",
    " 'metadata',\n",
    " 'objmag',\n",
    " 'region_names',\n",
    " 'save_regions',\n",
    " 'view_volumes'\n",
    "\"\"\"\n",
    "#print(kkpo.region_names[0])\n",
    "#interval, timepoint_names, channel_names, illum_names, plane_names = kkpo.get_region_info(kkpo.region_names[0])\n",
    "#print(interval, timepoint_names, channel_names, illum_names, plane_names)\n",
    "kkpo.save_regions(overwrite = True, save_vol = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 18.00 GiB </td>\n",
       "                        <td> 1.50 GiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (12, 192, 2048, 2048) </td>\n",
       "                        <td> (1, 192, 2048, 2048) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 3 Graph Layers </td>\n",
       "                        <td> 12 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> uint16 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"382\" height=\"192\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"2\" y1=\"0\" x2=\"2\" y2=\"25\" />\n",
       "  <line x1=\"4\" y1=\"0\" x2=\"4\" y2=\"25\" />\n",
       "  <line x1=\"6\" y1=\"0\" x2=\"6\" y2=\"25\" />\n",
       "  <line x1=\"8\" y1=\"0\" x2=\"8\" y2=\"25\" />\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" />\n",
       "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"25\" />\n",
       "  <line x1=\"14\" y1=\"0\" x2=\"14\" y2=\"25\" />\n",
       "  <line x1=\"16\" y1=\"0\" x2=\"16\" y2=\"25\" />\n",
       "  <line x1=\"19\" y1=\"0\" x2=\"19\" y2=\"25\" />\n",
       "  <line x1=\"21\" y1=\"0\" x2=\"21\" y2=\"25\" />\n",
       "  <line x1=\"23\" y1=\"0\" x2=\"23\" y2=\"25\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >12</text>\n",
       "  <text x=\"45.412617\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,45.412617,12.706308)\">1</text>\n",
       "\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"117\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"95\" y1=\"120\" x2=\"117\" y2=\"142\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"95\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"117\" y1=\"22\" x2=\"117\" y2=\"142\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"95.0,0.0 117.49187238314175,22.49187238314175 117.49187238314175,142.49187238314175 95.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"215\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"117\" y1=\"22\" x2=\"237\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"117\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"215\" y1=\"0\" x2=\"237\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"95.0,0.0 215.0,0.0 237.49187238314175,22.49187238314175 117.49187238314175,22.49187238314175\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"117\" y1=\"22\" x2=\"237\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"117\" y1=\"142\" x2=\"237\" y2=\"142\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"117\" y1=\"22\" x2=\"117\" y2=\"142\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"237\" y1=\"22\" x2=\"237\" y2=\"142\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"117.49187238314175,22.49187238314175 237.49187238314175,22.49187238314175 237.49187238314175,142.49187238314175 117.49187238314175,142.49187238314175\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"177.491872\" y=\"162.491872\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >2048</text>\n",
       "  <text x=\"257.491872\" y=\"82.491872\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,257.491872,82.491872)\">2048</text>\n",
       "  <text x=\"96.245936\" y=\"151.245936\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,96.245936,151.245936)\">192</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<_map_read_frame, shape=(12, 192, 2048, 2048), dtype=uint16, chunksize=(1, 192, 2048, 2048), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dask_image.imread import imread as dask_read\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "file_path = Path('/Volumes/bigData/kkpo_testing/song')\n",
    "region_name = 'R0000'\n",
    "ch_name = 'C01'\n",
    "channel_array = dask_read(file_path /  f'*{region_name}*{ch_name}*.tif')\n",
    "channel_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 192, 2048, 2048)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_array.chunksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 8.00 MiB </td>\n",
       "                        <td> 8.00 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (2048, 2048) </td>\n",
       "                        <td> (2048, 2048) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 6 Graph Layers </td>\n",
       "                        <td> 1 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> uint16 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,120.0 0.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >2048</text>\n",
       "  <text x=\"140.000000\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,140.000000,60.000000)\">2048</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<amax-aggregate, shape=(2048, 2048), dtype=uint16, chunksize=(2048, 2048), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.max(channel_array[0], axis = 0)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 2048)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.chunksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Array chunk size or shape is unknown. Possible solution with x.compute_chunk_sizes()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/array/chunk.py:418\u001b[0m, in \u001b[0;36mgetitem\u001b[0;34m(obj, index)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 418\u001b[0m     result \u001b[39m=\u001b[39m obj[index]\n\u001b[1;32m    419\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 3-dimensional, but 4 were indexed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/bementmbp/Desktop/Scripts/Flamingo_scripts/multiprocessing.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bementmbp/Desktop/Scripts/Flamingo_scripts/multiprocessing.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39;49mcompute_chunk_sizes()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/array/core.py:1508\u001b[0m, in \u001b[0;36mArray.compute_chunk_sizes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     c\u001b[39m.\u001b[39mappend(\u001b[39mtuple\u001b[39m(chunk_shapes[s]))\n\u001b[1;32m   1505\u001b[0m \u001b[39m# `map_blocks` assigns numpy dtypes\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m \u001b[39m# cast chunk dimensions back to python int before returning\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m x\u001b[39m.\u001b[39m_chunks \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[0;32m-> 1508\u001b[0m     \u001b[39mtuple\u001b[39m(\u001b[39mint\u001b[39m(chunk) \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunks) \u001b[39mfor\u001b[39;00m chunks \u001b[39min\u001b[39;00m compute(\u001b[39mtuple\u001b[39;49m(c))[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1510\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/base.py:600\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     keys\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_keys__())\n\u001b[1;32m    598\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 600\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    601\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[1;32m     90\u001b[0m     pool\u001b[39m.\u001b[39;49msubmit,\n\u001b[1;32m     91\u001b[0m     pool\u001b[39m.\u001b[39;49m_max_workers,\n\u001b[1;32m     92\u001b[0m     dsk,\n\u001b[1;32m     93\u001b[0m     keys,\n\u001b[1;32m     94\u001b[0m     cache\u001b[39m=\u001b[39;49mcache,\n\u001b[1;32m     95\u001b[0m     get_id\u001b[39m=\u001b[39;49m_thread_get_id,\n\u001b[1;32m     96\u001b[0m     pack_exception\u001b[39m=\u001b[39;49mpack_exception,\n\u001b[1;32m     97\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m         _execute_task(task, data)  \u001b[39m# Re-execute locally\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         raise_exception(exc, tb)\n\u001b[1;32m    512\u001b[0m res, worker_id \u001b[39m=\u001b[39m loads(res_info)\n\u001b[1;32m    513\u001b[0m state[\u001b[39m\"\u001b[39m\u001b[39mcache\u001b[39m\u001b[39m\"\u001b[39m][key] \u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mif\u001b[39;00m exc\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[1;32m    318\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 319\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     task, data \u001b[39m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 224\u001b[0m     result \u001b[39m=\u001b[39m _execute_task(task, data)\n\u001b[1;32m    225\u001b[0m     \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m get_id()\n\u001b[1;32m    226\u001b[0m     result \u001b[39m=\u001b[39m dumps((result, \u001b[39mid\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m(_execute_task(a, cache) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m(_execute_task(a, cache) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/core.py:113\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m\"\"\"Do the actual work of collecting data and executing a function\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m \u001b[39mExamples\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m'foo'\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, \u001b[39mlist\u001b[39m):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m [_execute_task(a, cache) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arg]\n\u001b[1;32m    114\u001b[0m \u001b[39melif\u001b[39;00m istask(arg):\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/core.py:113\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m\"\"\"Do the actual work of collecting data and executing a function\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m \u001b[39mExamples\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m'foo'\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, \u001b[39mlist\u001b[39m):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m [_execute_task(a, cache) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arg]\n\u001b[1;32m    114\u001b[0m \u001b[39melif\u001b[39;00m istask(arg):\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m(_execute_task(a, cache) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/test/lib/python3.10/site-packages/dask/array/chunk.py:420\u001b[0m, in \u001b[0;36mgetitem\u001b[0;34m(obj, index)\u001b[0m\n\u001b[1;32m    418\u001b[0m     result \u001b[39m=\u001b[39m obj[index]\n\u001b[1;32m    419\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 420\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    421\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mArray chunk size or shape is unknown. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPossible solution with x.compute_chunk_sizes()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mowndata \u001b[39mand\u001b[39;00m obj\u001b[39m.\u001b[39msize \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m result\u001b[39m.\u001b[39msize:\n",
      "\u001b[0;31mValueError\u001b[0m: Array chunk size or shape is unknown. Possible solution with x.compute_chunk_sizes()"
     ]
    }
   ],
   "source": [
    "x = m.compute_chunk_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Array chunk size or shape is unknown. Possible solution with x.compute_chunk_sizes()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/napari-env/lib/python3.9/site-packages/dask/array/chunk.py:418\u001b[0m, in \u001b[0;36mgetitem\u001b[0;34m(obj, index)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 418\u001b[0m     result \u001b[39m=\u001b[39m obj[index]\n\u001b[1;32m    419\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 4-dimensional, but 5 were indexed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m channel_array\u001b[39m.\u001b[39;49mcompute_chunk_sizes()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/napari-env/lib/python3.9/site-packages/dask/array/core.py:1503\u001b[0m, in \u001b[0;36mArray.compute_chunk_sizes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     c\u001b[39m.\u001b[39mappend(\u001b[39mtuple\u001b[39m(chunk_shapes[s]))\n\u001b[1;32m   1500\u001b[0m \u001b[39m# `map_blocks` assigns numpy dtypes\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[39m# cast chunk dimensions back to python int before returning\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m x\u001b[39m.\u001b[39m_chunks \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[0;32m-> 1503\u001b[0m     \u001b[39mtuple\u001b[39m(\u001b[39mint\u001b[39m(chunk) \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunks) \u001b[39mfor\u001b[39;00m chunks \u001b[39min\u001b[39;00m compute(\u001b[39mtuple\u001b[39;49m(c))[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1504\u001b[0m )\n\u001b[1;32m   1505\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/napari-env/lib/python3.9/site-packages/dask/base.py:600\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     keys\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_keys__())\n\u001b[1;32m    598\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 600\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    601\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/napari-env/lib/python3.9/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[1;32m     90\u001b[0m     pool\u001b[39m.\u001b[39;49msubmit,\n\u001b[1;32m     91\u001b[0m     pool\u001b[39m.\u001b[39;49m_max_workers,\n\u001b[1;32m     92\u001b[0m     dsk,\n\u001b[1;32m     93\u001b[0m     keys,\n\u001b[1;32m     94\u001b[0m     cache\u001b[39m=\u001b[39;49mcache,\n\u001b[1;32m     95\u001b[0m     get_id\u001b[39m=\u001b[39;49m_thread_get_id,\n\u001b[1;32m     96\u001b[0m     pack_exception\u001b[39m=\u001b[39;49mpack_exception,\n\u001b[1;32m     97\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/napari-env/lib/python3.9/site-packages/dask/local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m         _execute_task(task, data)  \u001b[39m# Re-execute locally\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         raise_exception(exc, tb)\n\u001b[1;32m    512\u001b[0m res, worker_id \u001b[39m=\u001b[39m loads(res_info)\n\u001b[1;32m    513\u001b[0m state[\u001b[39m\"\u001b[39m\u001b[39mcache\u001b[39m\u001b[39m\"\u001b[39m][key] \u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/napari-env/lib/python3.9/site-packages/dask/local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mif\u001b[39;00m exc\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[1;32m    318\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 319\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/napari-env/lib/python3.9/site-packages/dask/local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     task, data \u001b[39m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 224\u001b[0m     result \u001b[39m=\u001b[39m _execute_task(task, data)\n\u001b[1;32m    225\u001b[0m     \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m get_id()\n\u001b[1;32m    226\u001b[0m     result \u001b[39m=\u001b[39m dumps((result, \u001b[39mid\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/napari-env/lib/python3.9/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/napari-env/lib/python3.9/site-packages/dask/array/chunk.py:420\u001b[0m, in \u001b[0;36mgetitem\u001b[0;34m(obj, index)\u001b[0m\n\u001b[1;32m    418\u001b[0m     result \u001b[39m=\u001b[39m obj[index]\n\u001b[1;32m    419\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 420\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    421\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mArray chunk size or shape is unknown. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPossible solution with x.compute_chunk_sizes()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mowndata \u001b[39mand\u001b[39;00m obj\u001b[39m.\u001b[39msize \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m result\u001b[39m.\u001b[39msize:\n",
      "\u001b[0;31mValueError\u001b[0m: Array chunk size or shape is unknown. Possible solution with x.compute_chunk_sizes()"
     ]
    }
   ],
   "source": [
    "channel_array.compute_chunk_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "m = da.max(channel_array[0], axis=0)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imwrite\n",
    "imwrite('/Users/bementmbp/Desktop/Max.tiff', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interact.kkpo import Kkpo\n",
    "file_path = '/Volumes/bigData/kkpo_testing/1_region_2i_mini'\n",
    "kkpo = Kkpo(file_path)\n",
    "kkpo.view_volumes('R0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_image.imread import imread as dask_read\n",
    "from pathlib import Path\n",
    "file_path = Path('/Volumes/bigData/kkpo_testing/song')\n",
    "region_name = 'R0000'\n",
    "ch_name = 'C01'\n",
    "left_illum = 'I0'\n",
    "right_illum = 'I1'\n",
    "plane_name = 'P00192'\n",
    "\n",
    "channel_array_left = dask_read(file_path / f'*{region_name}*{ch_name}_I0*.tif')\n",
    "#channel_array_right = dask_read(file_path / f'S000_t000000_V000_{region_name}_X000_Y000_{ch_name}_I1_D0_{plane_name}.tif')\n",
    "channel_array_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "tp=0\n",
    "tp_name = 0\n",
    "m = da.max(channel_array_left[tp], axis=0)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imwrite as tiff_write\n",
    "from pathlib import Path\n",
    "region_save_path = Path('/Users/bementmbp/Desktop')\n",
    "\n",
    "tiff_write(region_save_path / f'{region_name}_{ch_name}_{tp_name}_Max.tiff', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tifffile import imwrite as tiff_write\n",
    "import dask.array as da\n",
    "\n",
    "# create a random dask array with shape (12, 192, 2048, 2048)\n",
    "r_arr = da.random.random((12, 192, 2048, 2048), chunks=(1, 1, 2048, 2048))\n",
    "r_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = da.max(r_arr[0], axis=0)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compute_chunk_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_write('/Users/bementmbp/Desktop/test.tiff', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### same thing but with distributed client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# make client with 16 processes\n",
    "client = Client(n_workers=8)\n",
    "print(client)\n",
    "\n",
    "ims = dask_read(file_path + '/' + '*.tif')\n",
    "print(f'gathered {len(ims)} images and assembled them into a dask array of shape {ims.shape} with chunk size {ims.chunks}')\n",
    "\n",
    "# save volume as zarr\n",
    "with yaspin() as sp:\n",
    "    sp.text = f'Converting full volume to zarr, please be patient...'\n",
    "    start = time.time()\n",
    "    da.to_zarr(ims[:,:,::8,::8], dask_vol_path, overwrite=True)\n",
    "    end = time.time()\n",
    "    print(f'Saved channel zarr in {round(end - start, 3)} seconds')\n",
    "\n",
    "# save max projection\n",
    "with tqdm(total=len(files)) as max_pbar:\n",
    "    max_pbar.set_description('Saving max projections')\n",
    "    for tp, tp_name in enumerate(['t000000', 't000001', 't000002', 't000003', 't000004']):\n",
    "        tiff_write(dask_max_path + '/' + f'{tp_name}_Max.tiff', np.max(ims[tp,:,:,:], axis=0))\n",
    "        max_pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with client and explicit parallelization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import skimage\n",
    "\n",
    "# make client with 16 processes\n",
    "client = Client()\n",
    "print(client)\n",
    "\n",
    "ims = dask_read(file_path + '/' + '*.tif')\n",
    "print(f'gathered {len(ims)} images and assembled them into a dask array of shape {ims.shape} with chunk size {ims.chunks}')\n",
    "\n",
    "#for tp, tp_name in enumerate(['t000000', 't000001', 't000002', 't000003', 't000004']):\n",
    "max = delayed(np.max(ims[:,:,:,:], axis=0))\n",
    "    #save = delayed(tiff_write(dask_max_path + '/' + f'{tp_name}_Max.tiff', max))\n",
    "\n",
    "def save_file(arr, block_info=None):\n",
    "    \"\"\" Save file to foo-x-y.tif, where x and y are block locations \"\"\"\n",
    "    filename = \"foo-\" + \"-\".join(map(str, block_info[0][\"chunk-location\"])) + \".tif\"\n",
    "    skimage.io.imsave(filename, arr)\n",
    "    return arr\n",
    "\n",
    "s = delayed(max.map_blocks(save_file, dtype=max.dtype))#.compute())       # call function on every block\n",
    "\n",
    "max.visualize()\n",
    "s.visualize()\n",
    "s.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('kkpo-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4cc8de4d070410aefe810673c90d022fcb4e8c9b6b7801eb4100474770f3f11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
